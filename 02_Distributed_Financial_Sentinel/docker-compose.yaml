# =================================
# Airflow Docker Compose File
# =================================
# Startup sequence: postgres -> webserver + scheduler (parallel)


version: '3.8'

services:
  # ----------------------------------------
  # 1. Core Database (Postgres)
  # Stores Airflow metadata and business data
  # ----------------------------------------
  postgres:
    image: postgres:13
    container_name: pipeline-db
    environment:
      - POSTGRES_USER=${POSTGRES_USER:-airflow}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD:-airflow}
      - POSTGRES_DB=${POSTGRES_DB:-airflow}
    ports:
      # Exposed for remote workers (HK/JP) to write back data
      # Security Note: Protected by UFW/IPTables on host machine
      - "5432:5432"
    volumes:
      - postgres-db-volume:/var/lib/postgresql/data
      - ./infra/init-db:/docker-entrypoint-initdb.d
    healthcheck:
      test: ["CMD", "pg_isready", "-U", "airflow"]
      interval: 5s
      retries: 5
    restart: always

  # ----------------------------------------
  # 2. Airflow Webserver (UI)
  # ----------------------------------------
  airflow-webserver:
    image: apache/airflow:2.7.1
    container_name: airflow-webserver
    command: webserver

    # Airflow Web UI: http://<US_IP>:8080
    ports:
      - "8080:8080"

    environment:
      # Use LocalExecutor, suitable for small to medium workloads
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor

      # Database connection string (credentials from .env file)
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://${POSTGRES_USER:-airflow}:${POSTGRES_PASSWORD:-airflow}@postgres/airflow
      - AIRFLOW__CORE__LOAD_EXAMPLES=False

      # Key for encrypting connection credentials
      - AIRFLOW__CORE__FERNET_KEY=${AIRFLOW_FERNET_KEY}
    volumes:
      # Mount project directories: DAGs, Logs, and Plugins
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins

      # Mounting Host SSH keys for remote execution capability
      # :ro means read-only (for security)
      # require SSH key pair configured on host machine
      - /root/.ssh:/home/airflow/.ssh:ro
    
    # Start only after postgres health check pass
    depends_on:
      postgres:
        condition: service_healthy
    restart: always

  # ----------------------------------------
  # 3. Airflow Scheduler
  # ----------------------------------------
  airflow-scheduler:
    image: apache/airflow:2.7.1
    container_name: airflow-scheduler
    command: scheduler

    # Shares database and exexcutor configuration with webserver
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://${POSTGRES_USER:-airflow}:${POSTGRES_PASSWORD:-airflow}@postgres/airflow
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
    volumes:
      - ./dags:/opt/airflow/dags
      - ./logs:/opt/airflow/logs
      - ./plugins:/opt/airflow/plugins
      - /root/.ssh:/home/airflow/.ssh:ro
    depends_on:
      postgres:
        condition: service_healthy
    restart: always

# Define Volumes for Persistent Storage
# Volume persist after container deletion
# Normal folder : /var/lib/docker/volumes/
volumes:
  postgres-db-volume: