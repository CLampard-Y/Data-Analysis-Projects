{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ed9a121",
   "metadata": {},
   "source": [
    "# 04 Uplift Modeling (S/T/X-Learner)\n",
    "\n",
    "This notebook follows Phase 2 MVP 2.4: CATE estimation via S-Learner / T-Learner / X-Learner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "89367063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[UTC+8] Run timestamp: 2026-02-24 14:38:39 +0800\n",
      "Figures will be saved to: outputs\\figures\n",
      "Loaded: data\\processed\\hillstrom_features.csv\n",
      "Loaded PS vector from: data\\processed\\hillstrom_ps.csv\n",
      "df.shape=(64000, 16) | X.shape=(64000, 9) | train=(44800, 9) | test=(19200, 9) | T.mean(full)=0.6671 | T.mean(train)=0.6671 | T.mean(test)=0.6671\n",
      "ps.mean(full)=0.6671 | ps.std(full)=0.0039\n",
      "Covariates (n=9): ['recency', 'history', 'mens', 'womens', 'newbie', 'channel_Phone', 'channel_Web', 'zip_Surburban', 'zip_Urban']\n"
     ]
    }
   ],
   "source": [
    "# ======================================================\n",
    "# Section 0 (Cell 1/1): Setup\n",
    "# ======================================================\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone, timedelta\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yaml\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Timezone anchoring for reproducibility\n",
    "TZ_UTC8 = timezone(timedelta(hours=8))\n",
    "run_ts_utc8 = datetime.now(TZ_UTC8).strftime('%Y-%m-%d %H:%M:%S %z')\n",
    "print(f\"[UTC+8] Run timestamp: {run_ts_utc8}\")\n",
    "\n",
    "# Project root resolution (avoid hardcoding)\n",
    "project_root = Path.cwd()\n",
    "if project_root.name == 'notebooks':\n",
    "    project_root = project_root.parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.insert(0, str(project_root))\n",
    "os.chdir(project_root)\n",
    "\n",
    "# Plot style\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 13\n",
    "sns.set_palette('Set2')\n",
    "\n",
    "# Load config (config.yml / config.yaml)\n",
    "config_candidates = [project_root / 'configs' / 'config.yaml', project_root / 'configs' / 'config.yml']\n",
    "config_path = next((p for p in config_candidates if p.exists()), None)\n",
    "if config_path is None:\n",
    "    raise FileNotFoundError(f\"No config file found. Searched: {[str(p) for p in config_candidates]}\")\n",
    "with open(config_path, 'r', encoding='utf-8') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "features_path = Path(config['paths']['features_data'])\n",
    "assert features_path.exists(), f\"Feature file not found: {features_path}\"\n",
    "\n",
    "figures_dir = Path(config['paths'].get('figures_dir', 'outputs/figures/'))\n",
    "figures_dir.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"Figures will be saved to: {figures_dir}\")\n",
    "\n",
    "# Load features\n",
    "df = pd.read_csv(features_path)\n",
    "assert isinstance(df, pd.DataFrame) and len(df) > 0, \"Loaded features DataFrame is empty\"\n",
    "print(f\"Loaded: {features_path}\")\n",
    "\n",
    "treatment_col = config['data']['treatment_col']\n",
    "outcome_col = config['data']['outcome_col']\n",
    "spend_col = config['data']['spend_col']\n",
    "covariates = config['data']['covariates']\n",
    "\n",
    "missing_covs = [c for c in covariates if c not in df.columns]\n",
    "assert len(missing_covs) == 0, f\"Missing covariates in df: {missing_covs}\"\n",
    "assert treatment_col in df.columns, f\"Missing required column: {treatment_col}\"\n",
    "assert outcome_col in df.columns, f\"Missing required column: {outcome_col}\"\n",
    "assert spend_col in df.columns, f\"Missing required column: {spend_col}\"\n",
    "\n",
    "# Split X, T, Y\n",
    "X = df[covariates].copy()\n",
    "T = pd.to_numeric(df[treatment_col], errors='coerce').astype(int)\n",
    "Y = pd.to_numeric(df[outcome_col], errors='coerce').astype(int)\n",
    "\n",
    "assert X.isnull().sum().sum() == 0, \"X contains NaN\"\n",
    "assert set(pd.unique(T)).issubset({0, 1}), \"T must be binary (0/1)\"\n",
    "assert set(pd.unique(Y)).issubset({0, 1}), \"Y must be binary (0/1)\"\n",
    "\n",
    "# Load or compute PS vector\n",
    "# Requests \"load features + PS vector\"; if the persisted PS artifact is not found,\n",
    "# we compute PS via LogisticRegression (estimate_ps) and persist it for reproducibility.\n",
    "ps_path = Path(config['paths'].get('ps_data', 'data/processed/hillstrom_ps.csv'))\n",
    "ps = None\n",
    "if ps_path.exists():\n",
    "    ps_df = pd.read_csv(ps_path)\n",
    "    if 'ps' not in ps_df.columns:\n",
    "        raise ValueError(f\"PS file missing 'ps' column: {ps_path}\")\n",
    "    ps = pd.to_numeric(ps_df['ps'], errors='coerce').to_numpy(dtype=float)\n",
    "    if len(ps) != len(df):\n",
    "        raise ValueError(f\"PS length mismatch: len(ps)={len(ps)} vs len(df)={len(df)}\")\n",
    "    print(f\"Loaded PS vector from: {ps_path}\")\n",
    "else:\n",
    "    from src.causal import estimate_ps\n",
    "    ps, _ = estimate_ps(X, T, random_state=int(config.get('general', {}).get('random_state', 42)))\n",
    "    ps_out = pd.DataFrame({'ps': ps.astype(float)})\n",
    "    ps_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    ps_out.to_csv(ps_path, index=False)\n",
    "    print(f\"Computed PS vector and saved to: {ps_path}\")\n",
    "\n",
    "ps = np.asarray(ps, dtype=float).reshape(-1)\n",
    "assert np.isfinite(ps).all(), \"ps contains NaN/inf\"\n",
    "assert ps.min() >= 0.0 and ps.max() <= 1.0, \"ps must be within [0, 1]\"\n",
    "\n",
    "# Train/Test split (architecture review adjustment #6)\n",
    "X_train, X_test, T_train, T_test, Y_train, Y_test, ps_train, ps_test = train_test_split(\n",
    "    X,\n",
    "    T,\n",
    "    Y,\n",
    "    ps,\n",
    "    test_size=0.3,\n",
    "    random_state=int(config.get('general', {}).get('random_state', 42)),\n",
    "    stratify=T,\n",
    ")\n",
    "\n",
    "assert len(X_train) == len(T_train) == len(Y_train) == len(ps_train), \"Train split length mismatch\"\n",
    "assert len(X_test) == len(T_test) == len(Y_test) == len(ps_test), \"Test split length mismatch\"\n",
    "\n",
    "print(\n",
    "    f\"df.shape={df.shape} | X.shape={X.shape} | \"\n",
    "    f\"train={X_train.shape} | test={X_test.shape} | \"\n",
    "    f\"T.mean(full)={T.mean():.4f} | T.mean(train)={np.mean(T_train):.4f} | T.mean(test)={np.mean(T_test):.4f}\"\n",
    ")\n",
    "print(f\"ps.mean(full)={ps.mean():.4f} | ps.std(full)={ps.std():.4f}\")\n",
    "print(f\"Covariates (n={len(covariates)}): {covariates}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2449c757",
   "metadata": {},
   "source": [
    "## Section 1: S-Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45e4040e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>1%</th>\n",
       "      <th>5%</th>\n",
       "      <th>50%</th>\n",
       "      <th>95%</th>\n",
       "      <th>99%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cate_s</th>\n",
       "      <td>19200.0</td>\n",
       "      <td>0.004402</td>\n",
       "      <td>0.004021</td>\n",
       "      <td>-0.011254</td>\n",
       "      <td>-0.003266</td>\n",
       "      <td>-0.000601</td>\n",
       "      <td>0.00377</td>\n",
       "      <td>0.011537</td>\n",
       "      <td>0.018345</td>\n",
       "      <td>0.036114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count      mean       std       min        1%        5%      50%  \\\n",
       "cate_s  19200.0  0.004402  0.004021 -0.011254 -0.003266 -0.000601  0.00377   \n",
       "\n",
       "             95%       99%       max  \n",
       "cate_s  0.011537  0.018345  0.036114  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max(|cate_s|) = 0.036114\n",
      "Expected (RCT) rough range: [-0.02, 0.02] | observed min=-0.011254, max=0.036114\n"
     ]
    }
   ],
   "source": [
    "# ======================================================\n",
    "# Section 1 (Cell 1/1): Fit S-Learner on train, predict CATE on test\n",
    "# ======================================================\n",
    "\n",
    "import importlib\n",
    "import src.uplift\n",
    "importlib.reload(src.uplift)\n",
    "from src.uplift import fit_s_learner\n",
    "\n",
    "uplift_cfg = config.get('uplift', {})\n",
    "n_estimators = int(uplift_cfg.get('n_estimators', 100))\n",
    "max_depth = int(uplift_cfg.get('max_depth', 5))\n",
    "random_state = int(config.get('general', {}).get('random_state', 42))\n",
    "\n",
    "cate_s = fit_s_learner(\n",
    "    X_train,\n",
    "    T_train,\n",
    "    Y_train,\n",
    "    X_pred=X_test,\n",
    "    n_estimators=n_estimators,\n",
    "    max_depth=max_depth,\n",
    "    random_state=random_state,\n",
    ")\n",
    "\n",
    "assert isinstance(cate_s, np.ndarray), 'cate_s must be a numpy.ndarray'\n",
    "assert len(cate_s) == len(X_test), 'CATE length must match test sample size'\n",
    "assert np.isfinite(cate_s).all(), 'CATE contains NaN/inf'\n",
    "\n",
    "cate_s_series = pd.Series(cate_s, name='cate_s')\n",
    "display(cate_s_series.describe(percentiles=[0.01, 0.05, 0.5, 0.95, 0.99]).to_frame().T)\n",
    "\n",
    "max_abs = float(np.max(np.abs(cate_s)))\n",
    "print(f\"max(|cate_s|) = {max_abs:.6f}\")\n",
    "if max_abs > 0.10:\n",
    "    print('[DQ] CATE magnitude > 0.10. Check model calibration / leakage / feature pipeline.')\n",
    "\n",
    "# Expected scale (Hillstrom RCT): roughly within [-0.02, 0.02]\n",
    "print(f\"Expected (RCT) rough range: [-0.02, 0.02] | observed min={cate_s.min():.6f}, max={cate_s.max():.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827ef9f2",
   "metadata": {},
   "source": [
    "### Section 1 Summary\n",
    "\n",
    "**Model**: S-Learner\n",
    "- Workflow: S-Learner 是基于单模型的 CATE 估计方法。\n",
    "\n",
    "        1. (训练单一模型) 把 Treatment 同样作为特征, 训练模型 f(X, T)\n",
    "        2. (反事实预测) 对所有用户分别强制计算 f(X, T = 1) 和 f(X, T = 0)\n",
    "        3. (计算 CATE) `CATE = f(X, T = 1) - f(X, T = 0)\n",
    "\n",
    "- Advantage: 训练简单, 无需复杂的数据训练流程\n",
    "- Disadvantage: 当 treatment 效应较小时（如本数据集的 RCT 场景），模型可能忽略 `T` 特征（正则化将其系数压向零），导致 **CATE ≈ 0** (如此处 CATE 均值为 0.0044, 这属于该模型的结构性缺陷, 非实现 BUG)\n",
    "\n",
    "后续的 **T-Learner** 通过分离建模 来规避这一问题"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28fa9bff",
   "metadata": {},
   "source": [
    "## Section 2: T-Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "901a2884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>1%</th>\n",
       "      <th>5%</th>\n",
       "      <th>50%</th>\n",
       "      <th>95%</th>\n",
       "      <th>99%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cate_t</th>\n",
       "      <td>19200.0</td>\n",
       "      <td>0.005302</td>\n",
       "      <td>0.00568</td>\n",
       "      <td>-0.025868</td>\n",
       "      <td>-0.00808</td>\n",
       "      <td>-0.002134</td>\n",
       "      <td>0.004505</td>\n",
       "      <td>0.015377</td>\n",
       "      <td>0.024571</td>\n",
       "      <td>0.047489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count      mean      std       min       1%        5%       50%  \\\n",
       "cate_t  19200.0  0.005302  0.00568 -0.025868 -0.00808 -0.002134  0.004505   \n",
       "\n",
       "             95%       99%       max  \n",
       "cate_t  0.015377  0.024571  0.047489  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max(|cate_t|) = 0.047489\n",
      "Expected (RCT) rough range: [-0.02, 0.02] | observed min=-0.025868, max=0.047489\n"
     ]
    }
   ],
   "source": [
    "# ======================================================\n",
    "# Section 2 (Cell 1/1): Fit T-Learner on train, predict CATE on test\n",
    "# ======================================================\n",
    "\n",
    "import importlib\n",
    "import src.uplift\n",
    "importlib.reload(src.uplift)\n",
    "from src.uplift import fit_t_learner\n",
    "\n",
    "uplift_cfg = config.get('uplift', {})\n",
    "n_estimators = int(uplift_cfg.get('n_estimators', 100))\n",
    "max_depth = int(uplift_cfg.get('max_depth', 5))\n",
    "random_state = int(config.get('general', {}).get('random_state', 42))\n",
    "\n",
    "cate_t = fit_t_learner(\n",
    "    X_train,\n",
    "    T_train,\n",
    "    Y_train,\n",
    "    X_pred=X_test,\n",
    "    n_estimators=n_estimators,\n",
    "    max_depth=max_depth,\n",
    "    random_state=random_state,\n",
    ")\n",
    "\n",
    "assert isinstance(cate_t, np.ndarray), 'cate_t must be a numpy.ndarray'\n",
    "assert len(cate_t) == len(X_test), 'CATE length must match test sample size'\n",
    "assert np.isfinite(cate_t).all(), 'CATE contains NaN/inf'\n",
    "\n",
    "cate_t_series = pd.Series(cate_t, name='cate_t')\n",
    "display(cate_t_series.describe(percentiles=[0.01, 0.05, 0.5, 0.95, 0.99]).to_frame().T)\n",
    "\n",
    "max_abs = float(np.max(np.abs(cate_t)))\n",
    "print(f\"max(|cate_t|) = {max_abs:.6f}\")\n",
    "if max_abs > 0.10:\n",
    "    print('[DQ] CATE magnitude > 0.10. Check model calibration / leakage / feature pipeline.')\n",
    "\n",
    "# Expected scale (Hillstrom RCT): roughly within [-0.02, 0.02]\n",
    "print(f\"Expected (RCT) rough range: [-0.02, 0.02] | observed min={cate_t.min():.6f}, max={cate_t.max():.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c499fc77",
   "metadata": {},
   "source": [
    "### Section 2 Summary\n",
    "**Model**: T-Learner \n",
    "\n",
    "- Workflow: S-Learner 是基于两个独立模型的 CATE 估计方法。\n",
    "\n",
    "        1. (分组训练模型) 分别在 Treatment 和 Control 组上训练两个模型 model_1 和 model_0\n",
    "        2. (反事实预测) 分别用 model_1 和 model_0 预测 Treatment 和 Control 组的效应\n",
    "                model_1: μ₁(x) = E[Y|X=x, T=1]\n",
    "                model_0: μ₀(x) = E[Y|X=x, T=0]\n",
    "        3. (计算 CATE) `CATE = μ₁(x) - μ₀(x)\n",
    "\n",
    "- Advantage: 直观上，当 treatment 效应较小且模型容易忽略 `T` 特征时，T-Learner 通常比 S-Learner 更容易“看到”两组 outcome 模型的差异\n",
    "- Disadvantage: 通过两个独立模型计算 CATE, 可能会导致误差进一步增大\n",
    "\n",
    "后续的 **X-Learner** 通过分离建模, 交叉估计与 PS 加权来规避这一问题，并在不平衡样本（T:C=2:1）下更具理论优势。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ffe757c",
   "metadata": {},
   "source": [
    "## Section 3: X-Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08571db0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>1%</th>\n",
       "      <th>5%</th>\n",
       "      <th>50%</th>\n",
       "      <th>95%</th>\n",
       "      <th>99%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cate_x</th>\n",
       "      <td>19200.0</td>\n",
       "      <td>0.004494</td>\n",
       "      <td>0.005865</td>\n",
       "      <td>-0.065357</td>\n",
       "      <td>-0.012522</td>\n",
       "      <td>-0.003793</td>\n",
       "      <td>0.004372</td>\n",
       "      <td>0.013121</td>\n",
       "      <td>0.023036</td>\n",
       "      <td>0.046513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          count      mean       std       min        1%        5%       50%  \\\n",
       "cate_x  19200.0  0.004494  0.005865 -0.065357 -0.012522 -0.003793  0.004372   \n",
       "\n",
       "             95%       99%       max  \n",
       "cate_x  0.013121  0.023036  0.046513  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max(|cate_x|) = 0.065357\n",
      "Expected (RCT) rough range: [-0.02, 0.02] | observed min=-0.065357, max=0.046513\n"
     ]
    }
   ],
   "source": [
    "# ======================================================\n",
    "# Section 3 (Cell 1/1): Fit X-Learner on train, predict CATE on test\n",
    "# ======================================================\n",
    "\n",
    "import importlib\n",
    "import src.uplift\n",
    "importlib.reload(src.uplift)\n",
    "from src.uplift import fit_x_learner\n",
    "\n",
    "uplift_cfg = config.get('uplift', {})\n",
    "n_estimators = int(uplift_cfg.get('n_estimators', 100))\n",
    "max_depth = int(uplift_cfg.get('max_depth', 5))\n",
    "random_state = int(config.get('general', {}).get('random_state', 42))\n",
    "\n",
    "cate_x = fit_x_learner(\n",
    "    X_train,\n",
    "    T_train,\n",
    "    Y_train,\n",
    "    ps_train,\n",
    "    X_pred=X_test,\n",
    "    ps_pred=ps_test,\n",
    "    n_estimators=n_estimators,\n",
    "    max_depth=max_depth,\n",
    "    random_state=random_state,\n",
    ")\n",
    "\n",
    "assert isinstance(cate_x, np.ndarray), 'cate_x must be a numpy.ndarray'\n",
    "assert len(cate_x) == len(X_test), 'CATE length must match test sample size'\n",
    "assert np.isfinite(cate_x).all(), 'CATE contains NaN/inf'\n",
    "\n",
    "cate_x_series = pd.Series(cate_x, name='cate_x')\n",
    "display(cate_x_series.describe(percentiles=[0.01, 0.05, 0.5, 0.95, 0.99]).to_frame().T)\n",
    "\n",
    "max_abs = float(np.max(np.abs(cate_x)))\n",
    "print(f\"max(|cate_x|) = {max_abs:.6f}\")\n",
    "if max_abs > 0.10:\n",
    "    print('[DQ] CATE magnitude > 0.10. Check model calibration / leakage / feature pipeline.')\n",
    "\n",
    "# Expected scale (Hillstrom RCT): roughly within [-0.02, 0.02]\n",
    "print(f\"Expected (RCT) rough range: [-0.02, 0.02] | observed min={cate_x.min():.6f}, max={cate_x.max():.6f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d112dd2b",
   "metadata": {},
   "source": [
    "### Section 3 Summary\n",
    "**Model**: X-Learner\n",
    "\n",
    "- Workflow: X-Learner 是在 T-Learner 基础上, 进一步加入第二阶段模型 (计算伪残差) 及对样本进行 PS 加权处理的 CATE 估计方法。\n",
    "\n",
    "1) (分组训练模型) 分别在 Treatment 和 Control 组上训练两个模型 model_1 和 model_0 (同 T-Learner)\n",
    "2) (伪残差计算) 分别用 model_1 和 model_0 预测伪残差 (X₁, X₀ 分别表示 Treatment 和 Control 组用户)\n",
    "   - 在 Treatment 组用 Control 的 model_0 模型来估计 μ₀(X₁)，得到 D₁ = Y₁ - μ₀(X₁)\n",
    "   - 在 Control 组用 Treatment 的 model_1 模型来估计 μ₁(X₀)，得到 D₀ = μ₁(X₀) - Y₀\n",
    "3) (回归模型) 利用两个残差来继续训练回归模型得到 τ₁(x) 和 τ₀(x)\n",
    "4) (PS 加权计算) CATE = = (1 - e(x)) · τ₁(x) + e(x) · τ₀(x)\n",
    "\n",
    "- Advantage: 本数据集中 `Treatment:Control ≈ 2:1`，Control 组样本更少。对于不平衡数据，X-Learner 相比 T-Learner 的优势在于：\n",
    "   -  **交叉估计（imputation）降低方差**\n",
    "\n",
    "   -  **PS 加权组合**\n",
    "   \n",
    "   直觉上可以理解为：通过 outcome 模型的交叉估计，少数组（Control）的信息不足可以借助多数组（Treatment）的模型来补偿；再通过 PS 加权把两侧估计合成一个更稳健的 CATE。\n",
    "\n",
    "- Disadvantage: 流程复杂"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "web3envv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
